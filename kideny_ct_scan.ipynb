{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Convolutional Neural Network (CNN) for Image Classification\n",
    "\n",
    "## Tags:\n",
    "- CNN\n",
    "- Image Classification\n",
    "- Deep Learning\n",
    "- TensorFlow\n",
    "- Keras\n",
    "\n",
    "## Description:\n",
    "In this notebook, we will implement a Convolutional Neural Network (CNN) using TensorFlow and Keras for image classification. We'll use the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 classes, such as airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3709 imges of Cyst\n",
      "There are 5077 imges of Normal\n",
      "There are 1377 imges of Stone\n",
      "There are 2283 imges of Tumor\n"
     ]
    }
   ],
   "source": [
    "source_path = \"/home/alrashidi/Desktop/Deep_learning_Models/CT_KIDNEY_DATASET_Normal_Cyst_Tumor_Stone/CT_KIDNEY_DATASET_Normal_Cyst_Tumor_Stone\"\n",
    "source_path_Cyst = os.path.join(source_path, \"Cyst\")\n",
    "source_path_Normal = os.path.join(source_path, \"Normal\")\n",
    "source_path_Stone = os.path.join(source_path, \"Stone\")\n",
    "source_path_Tumor = os.path.join(source_path, \"Tumor\")\n",
    "\n",
    "# Deletes all non_imags files\n",
    "# !find {source_path} -type f ! -name \"*.jpg\" -exec rm {} +\n",
    "\n",
    "# os.listdir reruns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir(source_path_Cyst))} imges of Cyst\")\n",
    "print(f\"There are {len(os.listdir(source_path_Normal))} imges of Normal\")\n",
    "print(f\"There are {len(os.listdir(source_path_Stone))} imges of Stone\")\n",
    "print(f\"There are {len(os.listdir(source_path_Tumor))} imges of Tumor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training validation directions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created: training_validation_CDK/training, training_validation_CDK/validation\n",
      "training_validation_CDK/validation\n",
      "training_validation_CDK/training\n",
      "training_validation_CDK/validation/Stone\n",
      "training_validation_CDK/validation/Normal\n",
      "training_validation_CDK/validation/Cyst\n",
      "training_validation_CDK/validation/Tumor\n",
      "training_validation_CDK/training/Stone\n",
      "training_validation_CDK/training/Normal\n",
      "training_validation_CDK/training/Cyst\n",
      "training_validation_CDK/training/Tumor\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = \"training_validation_CDK\"\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "    shutil.rmtree(root_dir)\n",
    "\n",
    "# Create Function\n",
    "def create_train_val_dirs(root_path) -> None:\n",
    "    \"\"\"\n",
    "    Create direcotries for the train and test sets\n",
    "\n",
    "    Args:\n",
    "       root_path (string) - the base directory path to create subdirectories from\n",
    "\n",
    "    Returns:\n",
    "       None\n",
    "    \"\"\"\n",
    "    # Create directories for training and validation sets\n",
    "    # Define the path for the train and validation sets\n",
    "\n",
    "    train_path = os.path.join(root_path, \"training\")\n",
    "    val_path = os.path.join(root_path, \"validation\")\n",
    "\n",
    "    # Create the traina and validation directories\n",
    "    os.makedirs(train_path)\n",
    "    os.makedirs(val_path)\n",
    "\n",
    "    # Inside each of the traina and validation directorues, create 'Cyst', 'Normal', 'Stone', 'Tumor' subdirectories\n",
    "    os.makedirs(os.path.join(train_path, \"Cyst\"))\n",
    "    os.makedirs(os.path.join(train_path, \"Normal\"))\n",
    "    os.makedirs(os.path.join(train_path, \"Stone\"))\n",
    "    os.makedirs(os.path.join(train_path, \"Tumor\"))\n",
    "    os.makedirs(os.path.join(val_path, \"Cyst\"))\n",
    "    os.makedirs(os.path.join(val_path, \"Normal\"))\n",
    "    os.makedirs(os.path.join(val_path, \"Stone\"))\n",
    "    os.makedirs(os.path.join(val_path, \"Tumor\"))\n",
    "    \"\"\"\n",
    "     /training_validation_CDK\n",
    "     |-- train\n",
    "     |   |-- Cyst \n",
    "     |   |-- Normal\n",
    "     |   |-- Stone \n",
    "     |   |-- Tumor \n",
    "     \n",
    "     |-- validation\n",
    "     |   |-- Cyst \n",
    "     |   |-- Normal\n",
    "     |   |-- Stone \n",
    "     |   |-- Tumor \n",
    "     \"\"\"\n",
    "    print(f\"Directories created: {train_path}, {val_path}\")\n",
    "\n",
    "try:\n",
    "    create_train_val_dirs(root_path=root_dir)\n",
    "except Exception as e:\n",
    "    # Code to handle the specific exception\n",
    "    raise ValueError(f\"An error occurred: {e}.\")\n",
    "\n",
    "# Test your create_train_val-dirs function\n",
    "for root_dir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(root_dir, subdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: split_data\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  \"\"\"\n",
    "  Splits the data into train and test sets\n",
    "\n",
    "  Args:\n",
    "    SOURCE_DIR (string): directory path containing the images\n",
    "    TRAINING_DIR (string): directory path to be used for training\n",
    "    VALIDATION_DIR (string): directory path to be used for validation\n",
    "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
    "\n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "  # Check if the directories exist; if not, create them\n",
    "  if not os.path.exists(TRAINING_DIR):\n",
    "    os.makedirs(TRAINING_DIR)\n",
    "  if not os.path.exists(VALIDATION_DIR):\n",
    "    os.makedirs(VALIDATION_DIR)\n",
    "  \n",
    "  # Get the list of files\n",
    "  files = os.listdir(SOURCE_DIR)\n",
    "\n",
    "  # Shuffle the list of files\n",
    "  random.sample(files, len(files))\n",
    "\n",
    "  # Calculate the split index based on SPLIT_SIZE\n",
    "  split_index = int(SPLIT_SIZE * len(files))\n",
    "\n",
    "  # Seoarate files into training and validation sets\n",
    "  training_files = files[:split_index]\n",
    "  validation_files = files[split_index:]\n",
    "\n",
    "  # Copy files to training directory \n",
    "  for file in training_files:\n",
    "    source = os.path.join(SOURCE_DIR, file)\n",
    "    destination = os.path.join(TRAINING_DIR, file)\n",
    "    if os.path.getsize(source) > 0:\n",
    "      copyfile(source, destination)\n",
    "    else:\n",
    "      print(f\"{file} is zero lenght, so ignoring.\")\n",
    "\n",
    "  # Copy files to validation directory \n",
    "  for file in validation_files:\n",
    "    source = os.path.join(SOURCE_DIR, file)\n",
    "    destination = os.path.join(VALIDATION_DIR, file)\n",
    "    if os.path.getsize(source) > 0:\n",
    "      copyfile(source, destination)\n",
    "    else:\n",
    "      print(f\"{file} is zero lenght, so ignoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your split_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Cyst a directory has 3709 images\n",
      "Original Normal a directory has 5077 images\n",
      "\n",
      "Original Stone a directory has 1377 images\n",
      "Original Tumor a directory has 2283 images\n",
      "\n",
      "There are 3338 images of Cyst for training\n",
      "There are 4569 images of Normal for training\n",
      "There are 1239 images of Stone for training\n",
      "There are 2054 images of Tumor for training\n",
      "There are 371 images of Cyst for validation\n",
      "There are 508 images of Normal for validation\n",
      "There are 138 images of Stone for validation\n",
      "There are 229 images of Tumor for validation\n"
     ]
    }
   ],
   "source": [
    "# Define path\n",
    "ROOT_DIR = \"CT_KIDNEY_DATASET_Normal_Cyst_Tumor_Stone/CT_KIDNEY_DATASET_Normal_Cyst_Tumor_Stone/\"\n",
    "Cyst_SOURCE_DIR  = f\"{ROOT_DIR}/Cyst\"\n",
    "Normal_SOURCE_DIR= f\"{ROOT_DIR}/Normal\"\n",
    "Stone_SOURCE_DIR = f\"{ROOT_DIR}/Stone\"\n",
    "Tumor_SOURCE_DIR = f\"{ROOT_DIR}/Tumor\"\n",
    "\n",
    "TRAINING_DIR = \"training_validation_CDK/training\"\n",
    "VALIDATION_DIR = \"training_validation_CDK/validation\"\n",
    "\n",
    "TRAINING_Cyst_DIR = os.path.join(TRAINING_DIR, \"Cyst\")\n",
    "TRAINING_Normal_DIR = os.path.join(TRAINING_DIR, \"Normal\")\n",
    "TRAINING_Stone_DIR = os.path.join(TRAINING_DIR, \"Stone\")\n",
    "TRAINING_Tumor_DIR = os.path.join(TRAINING_DIR, \"Tumor\")\n",
    "\n",
    "VALIDATION_Cyst_DIR = os.path.join  (VALIDATION_DIR, \"Cyst\")\n",
    "VALIDATION_Normal_DIR = os.path.join(VALIDATION_DIR, \"Normal\")\n",
    "VALIDATION_Stone_DIR = os.path.join (VALIDATION_DIR, \"Stone\")\n",
    "VALIDATION_Tumor_DIR = os.path.join (VALIDATION_DIR, \"Tumor\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "def directories_multiple(path):\n",
    "    if len(os.listdir(path)) > 0:\n",
    "       for file in os.scandir(path):\n",
    "           os.remove(file.path)\n",
    "\n",
    "# /Training\n",
    "directories_multiple(TRAINING_Cyst_DIR)\n",
    "directories_multiple(TRAINING_Normal_DIR)\n",
    "directories_multiple(TRAINING_Stone_DIR)\n",
    "directories_multiple(TRAINING_Tumor_DIR)\n",
    "# / Validation\n",
    "directories_multiple(VALIDATION_Cyst_DIR)\n",
    "directories_multiple(VALIDATION_Normal_DIR)\n",
    "directories_multiple(VALIDATION_Stone_DIR)\n",
    "directories_multiple(VALIDATION_Tumor_DIR)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Massages about zero length images should be printed out\n",
    "split_data(SOURCE_DIR=Cyst_SOURCE_DIR, TRAINING_DIR=TRAINING_Cyst_DIR , VALIDATION_DIR=VALIDATION_Cyst_DIR, SPLIT_SIZE=split_size)\n",
    "split_data(SOURCE_DIR=Normal_SOURCE_DIR, TRAINING_DIR=TRAINING_Normal_DIR, VALIDATION_DIR=VALIDATION_Normal_DIR, SPLIT_SIZE=split_size)\n",
    "split_data(SOURCE_DIR=Stone_SOURCE_DIR, TRAINING_DIR=TRAINING_Stone_DIR, VALIDATION_DIR=VALIDATION_Stone_DIR, SPLIT_SIZE=split_size )\n",
    "split_data(SOURCE_DIR=Tumor_SOURCE_DIR, TRAINING_DIR=TRAINING_Tumor_DIR, VALIDATION_DIR=VALIDATION_Tumor_DIR, SPLIT_SIZE=split_size)\n",
    "\n",
    "# The function should perform copies rather than moving images or original directories should contain unchan ged images\n",
    "print(f\"Original Cyst a directory has {len(os.listdir(Cyst_SOURCE_DIR))} images\")\n",
    "print(f\"Original Normal a directory has {len(os.listdir(Normal_SOURCE_DIR))} images\")\n",
    "print(f\"Original Stone a directory has {len(os.listdir(Stone_SOURCE_DIR))} images\")\n",
    "print(f\"Original Tumor a directory has {len(os.listdir(Tumor_SOURCE_DIR))} images\")\n",
    "\n",
    "# Training and validation splits. Check\n",
    "print(f\"There are {len(os.listdir(TRAINING_Cyst_DIR))} images of Cyst for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_Normal_DIR))} images of Normal for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_Stone_DIR))} images of Stone for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_Tumor_DIR))} images of Tumor for training\")\n",
    "#/ Validation\n",
    "print(f\"There are {len(os.listdir(VALIDATION_Cyst_DIR))} images of Cyst for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_Normal_DIR))} images of Normal for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_Stone_DIR))} images of Stone for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_Tumor_DIR))} images of Tumor for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11200 images belonging to 4 classes.\n",
      "Found 1246 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "## Image shape: 512 x 512 x 3 \n",
    "# FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  \"\"\"\n",
    "  Creates the training and validation data generators\n",
    "\n",
    "  Args:\n",
    "    TRAINING_DIR (string): directory path containing the training images\n",
    "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
    "\n",
    "  Returns:\n",
    "    train_generator, validation_generator - tuple containing the generators\n",
    "  \"\"\"\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (and set the arguments to agument the images)\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=45,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest')\n",
    "  # Pass the appropriate arguments to the flow_from_directory method for the training data\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=16,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      target_size=(512 , 512))\n",
    "  \n",
    "  # Instantiate the ImageDataGenerator class (with rescale)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "  # pass the appropriate argument to the flow_from_directory method for the trainig data\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=16,\n",
    "                                                                class_mode='categorical',\n",
    "                                                                target_size=(512, 512))\n",
    "  \n",
    "  # Return: Train, Validation\n",
    "  return train_generator, validation_generator\n",
    "\n",
    "# Test Generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR=TRAINING_DIR,\n",
    "                                                             VALIDATION_DIR=VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model \n",
    "\n",
    "Basics CNN,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function: create_model\n",
    "def create_model():\n",
    "\n",
    "    # Basic CNN\n",
    "    model = tf.keras.models.Sequential([\n",
    "            # Layer 1: Convolutional layer with 96 filters, kernel size 11x11, and ReLU activation\n",
    "            tf.keras.layers.Conv2D(96, (11,11), activation='rule', input_shape=(512, 512, 3)) ,\n",
    "            # Max pooling layer with pool size 2x2\n",
    "            tf.keras.layers.MaxPool2D(2,2) ,\n",
    "\n",
    "            # Layer 2: Convolutional layer with 256 filters, kernel size 5x5, and ReLU activation\n",
    "            tf.keras.layers.Conv2D(256, (5,5), activation='rule'),\n",
    "            # Max pooling layer with pool size 2x2\n",
    "            tf.keras.layers.MaxPool2D(2,2) ,\n",
    "\n",
    "            # Layer 2: Convolutional layer with 384 filters, kernel size 3x3, and ReLU activation\n",
    "            tf.keras.layers.Conv2D(384, (3,3), activation='rule') ,\n",
    "            # Max pooling layer with pool size 2x2\n",
    "            tf.keras.layers.MaxPool2D(2,2) ,\n",
    "\n",
    "            # Layer 2: Convolutional layer with 384 filters, kernel size 3x3, and ReLU activation\n",
    "            tf.keras.layers.Conv2D(384, (3,3), activation='rule') ,\n",
    "            # Max pooling layer with pool size 2x2\n",
    "            tf.keras.layers.MaxPool2D(2,2) ,\n",
    "\n",
    "            # Layer 2: Convolutional layer with 256 filters, kernel size 5x5, and ReLU activation\n",
    "            tf.keras.layers.Conv2D(384, (3,3), activation='rule') ,\n",
    "            # Max pooling layer with pool size 2x2\n",
    "            tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "            # Layer 2: Convolutional layer with 256 filters, kernel size 5x5, and ReLU activation\n",
    "            tf.keras.layers.Conv2D(256, (3,3), activation='rule'),\n",
    "            # Max pooling layer with pool size 2x2\n",
    "            tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "            # Flatten layer to convert 3D feature maps to 1D feature vectors\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            # Layer 7: Fully connected layer with 4096 units and ReLU activation\n",
    "            tf.keras.layers.Dense(4096, activation='relu'),\n",
    "            # Dropout layer with dropout rate 0.5 to reduce overfitting\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "            # Output layers use softmax activation funcation\n",
    "            tf.keras.layers.Dense(4, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                                         beta_1=0.9,\n",
    "                                         beta_2=0.999,\n",
    "                                         epsilon=1e-07\n",
    "                                         )\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    # categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the untrained model\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Accuracy and Loss for Traing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download History for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_history():\n",
    "    import pickle\n",
    "\n",
    "    # Save the history to a file\n",
    "    with open('history_augmented.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    print(\"History saved to 'history_augmented.pkl'\")\n",
    "\n",
    "# Call the function\n",
    "download_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "We successfully built and trained a CNN using TensorFlow and Keras for image classification on the CIFAR-10 dataset. The model achieved an accuracy of [insert accuracy here]% on the test set. Further improvements could be made by experimenting with different architectures, hyperparameters, and augmentation techniques.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlRashid",
   "language": "python",
   "name": "alrashid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
